Logging to ./experiments/fair_ppo/debug/
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.02e+03 |
|    ep_rew_mean     | 4.79e+03 |
| time/              |          |
|    fps             | 87       |
|    iterations      | 1        |
|    time_elapsed    | 46       |
|    total_timesteps | 4096     |
---------------------------------
------------------------------------------
| rollout/                |              |
|    benefit_max          | 0.534        |
|    benefit_min          | 0.224        |
|    ep_len_mean          | 1.02e+03     |
|    ep_rew_mean          | 5.22e+03     |
|    hard_bias_estimate   | 0.311        |
|    soft_bias_estimate   | 0.716        |
| time/                   |              |
|    fps                  | 58           |
|    iterations           | 2            |
|    time_elapsed         | 140          |
|    total_timesteps      | 8192         |
| train/                  |              |
|    approx_kl            | 0.0069492604 |
|    clip_fraction        | 0.0553       |
|    clip_range           | 0.2          |
|    entropy_loss         | -7.09        |
|    explained_variance   | -0.141       |
|    learning_rate        | 1e-05        |
|    loss                 | 9.87e+04     |
|    n_updates            | 10           |
|    policy_gradient_loss | nan          |
|    std                  | 1            |
|    value_loss           | 6.83e+03     |
|    value_loss_B         | 4.11e+04     |
|    value_loss_U         | 2.8e+03      |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    benefit_max          | 0.503        |
|    benefit_min          | 0.408        |
|    ep_len_mean          | 1.02e+03     |
|    ep_rew_mean          | 5.71e+03     |
|    hard_bias_estimate   | 0.0949       |
|    soft_bias_estimate   | 0.649        |
| time/                   |              |
|    fps                  | 67           |
|    iterations           | 3            |
|    time_elapsed         | 182          |
|    total_timesteps      | 12288        |
| train/                  |              |
|    approx_kl            | 0.0053881826 |
|    clip_fraction        | 0.039        |
|    clip_range           | 0.2          |
|    entropy_loss         | -7.09        |
|    explained_variance   | 0.128        |
|    learning_rate        | 1e-05        |
|    loss                 | 8.19e+04     |
|    n_updates            | 20           |
|    policy_gradient_loss | nan          |
|    std                  | 1            |
|    value_loss           | 6.85e+03     |
|    value_loss_B         | 3.65e+04     |
|    value_loss_U         | 2.67e+03     |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    benefit_max          | 0.582        |
|    benefit_min          | 0.456        |
|    ep_len_mean          | 1.02e+03     |
|    ep_rew_mean          | 6.17e+03     |
|    hard_bias_estimate   | 0.125        |
|    soft_bias_estimate   | 0.653        |
| time/                   |              |
|    fps                  | 73           |
|    iterations           | 4            |
|    time_elapsed         | 223          |
|    total_timesteps      | 16384        |
| train/                  |              |
|    approx_kl            | 0.0064883484 |
|    clip_fraction        | 0.0563       |
|    clip_range           | 0.2          |
|    entropy_loss         | -7.09        |
|    explained_variance   | 0.402        |
|    learning_rate        | 1e-05        |
|    loss                 | 7.89e+04     |
|    n_updates            | 30           |
|    policy_gradient_loss | nan          |
|    std                  | 1            |
|    value_loss           | 6.96e+03     |
|    value_loss_B         | 3.23e+04     |
|    value_loss_U         | 2.81e+03     |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    benefit_max          | 0.606        |
|    benefit_min          | 0.523        |
|    ep_len_mean          | 1.02e+03     |
|    ep_rew_mean          | 6.55e+03     |
|    hard_bias_estimate   | 0.083        |
|    soft_bias_estimate   | 0.649        |
| time/                   |              |
|    fps                  | 77           |
|    iterations           | 5            |
|    time_elapsed         | 264          |
|    total_timesteps      | 20480        |
| train/                  |              |
|    approx_kl            | 0.0062024323 |
|    clip_fraction        | 0.0515       |
|    clip_range           | 0.2          |
|    entropy_loss         | -7.09        |
|    explained_variance   | 0.633        |
|    learning_rate        | 1e-05        |
|    loss                 | 6.93e+04     |
|    n_updates            | 40           |
|    policy_gradient_loss | nan          |
|    std                  | 1            |
|    value_loss           | 6.3e+03      |
|    value_loss_B         | 2.81e+04     |
|    value_loss_U         | 3.12e+03     |
------------------------------------------
